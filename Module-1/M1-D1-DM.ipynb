{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    },
    "colab": {
      "name": "M1-D1-DM.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sigvehaug/CAS-Applied-Data-Science/blob/master/Module-1/M1-D1-DM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOSMpeOK06p8"
      },
      "source": [
        "Notebook 1, Module 1, Data and Data Management, CAS Applied Data Science, 2021-08-23, S. Haug, University of Bern.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljJDZt-n6zPw"
      },
      "source": [
        "Prerequisite for this notebook is some basic Python experience.\n",
        "\n",
        "Please also look at the first batch of [these slides](https://docs.google.com/presentation/d/1BrlQQGDnEpr8lBiEd9uO-Kw2-WOInAEP-cv-xdUwB4Y/edit?usp=sharing) before doing this notebook. They offer an introduction to data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAVKazfU06p-"
      },
      "source": [
        "# 1. Data Management\n",
        "\n",
        "Estimated study time is up to 2 hours. According to your background and how much you want to learn, you may need more or less. You are supposed to google, read manuals and chat with others during working through this notebook in order to benefit fully.\n",
        "\n",
        "**Learning outcomes - after completion you**\n",
        "- Know about data sources, types and formats (see lecture slides via link above)\n",
        "- Able to import and export data in Python\n",
        "- Able to do simple things with dataframes in Python\n",
        "- Know about data volumes, metadata and quality\n",
        "- Able to plot histograms and scatter plots in Python (tomorrow)\n",
        "\n",
        "**Documentation on Pandas DataFrame**\n",
        "- Python: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html\n",
        "\n",
        "## Outline\n",
        "\n",
        "     0. About data management\n",
        "     1. Getting used to Jupyter lab\n",
        "     2. Import datasets into a Python dataframe\n",
        "     3. Indexing on a dataframe\n",
        "     4. Sorting\n",
        "     5. Filtering\n",
        "     6. Exporting\n",
        "     7. Missing and bad data\n",
        "     8. Metadata\n",
        "     9. Working on the filesystem\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-86pc1PfWAT"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0o4Jxdy06qA"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xY2gyiE06qA"
      },
      "source": [
        "### 0. About data management"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFyhF-jp06qB"
      },
      "source": [
        "Handling or managing data involves many steps and technologies at many levels. Data my be colleccted by sensors. It can be a camera, a temperature sensor, a telescope, a microscope (with a camera), a microphone, a particle detector etc. Normally the data is then digitised, maybe preprocessed and written to some media in a certain format, e.g. hard disk. This part of the data management is normally taken care of by engineers.\n",
        "\n",
        "Data may also be collected from all sorts of databases, so data already collected somehow. Time series of financial data, customers, passengers, facebook likes, twitter tweets etc. This is data which is normally already on a media with some interface for access, e.g. paper to be read by a camera, a file on youtube, a table on wikipedia etc. We will look at some ways to collect such data. Some programming and computer skills are needed to do so. It may be that this part of the data management is taken care of by specialised computer scientists, but it may also be expected from a data scientist to have these skills.\n",
        "\n",
        "Analysing data with statisitical and machine learning tools, requires that the data is colleceted, cleaned and prepared for the tools. This is very often a very large part of a data analytics project and a prerequisite. It may involve removing bad data, filter out redundant and noisy data, unify the formats and types, transform the data etc.\n",
        "Thus, a data scientist must be able to perform this part of the data management. This notebook shows the basic operations with Python pandas. With other tools the concepts and operations are very similar.\n",
        "\n",
        "After the data analysis, after the extraction of information and the creation of knowledge, the data is often stored or archived for the future (if this seems cheaper than regenerating the data at a later point). In larger institutions this part of the data management may include educated librarians and others, not necessarily the data scientist.  \n",
        "\n",
        "**In this notebook we only look at a few examples on how to do datamanagement with dataframes. Pandas are extremly powerful and we cannot show everything in a couple of hours. You will become more and more experienced when you work on your module projects. Probably whatever you want to do with your dataframe, there is a way to do it. If not, it probably doesn't make much sense what wou want to do.**\n",
        "\n",
        "Any questions?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4HJ8cnp06qC"
      },
      "source": [
        "### 1. Getting used to Jupyter computational notebooks and Colab\n",
        "\n",
        "With Jupyter you can write rich text notebooks with executable code via your browser. There are several so-called kernels or computational back ends, i.e Python, R, Julia, bash etc can be supported. The text is written as Markdown. Latex is also supported (good for math). You can export the notebook in various formats, e.g. html. Everything can be done via the various tabs, however, the key shortcuts make you faster.\n",
        "\n",
        "*Useful key combinations*\n",
        "\n",
        "- Shift Enter or Control Enter = Run cell\n",
        "- Option Enter = Run cell and Insert new cell below\n",
        "\n",
        "*Exercises (10 min)*\n",
        "- Change and run this cell\n",
        "- Add a new cell and execute some python statement in it\n",
        "- Study the tabs in the menu of your jupyter (lab) notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tn_Bnh606qC"
      },
      "source": [
        "# Write some more Python code here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Yy0P4Q006qD"
      },
      "source": [
        "### 2. Import a dataset into a Pandas DataFrame\n",
        "\n",
        "Pandas is a Python Module/Library for data analysis and manipulation. It has the data structure DataFrame which is quite powerful. Features\n",
        "\n",
        "- DataFrame object for data manipulation with integrated indexing.\n",
        "- Tools for reading and writing data between in-memory data structures and different file formats.\n",
        "- Data alignment and integrated handling of missing data.\n",
        "- Reshaping and pivoting of data sets.\n",
        "- Label-based slicing, fancy indexing, and subsetting of large data sets.\n",
        "- Data structure column insertion and deletion.\n",
        "- Group by engine allowing split-apply-combine operations on data sets.\n",
        "- Data set merging and joining.\n",
        "- Hierarchical axis indexing to work with high-dimensional data in a lower-dimensional data structure.\n",
        "- Time series-functionality: Date range generation and frequency conversion, moving window statistics, moving window linear regressions, date shifting and lagging.\n",
        "\n",
        "The module is highly optimized for performance, with critical code parts written in Cython or C. Documentation here: https://pandas.pydata.org/pandas-docs/stable/api.html\n",
        "\n",
        "For input/output (I/O) there are methods for reading EXCEL, SQL databases, HTML tables, clipboard, SAS, STATA etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2va7jftt06qF"
      },
      "source": [
        "# Upload the local data file to colab\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fcu5tlR106qG"
      },
      "source": [
        "# import the python module pandas with the abbreviation pd\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKvS45Aq06qH"
      },
      "source": [
        "The dataframe method shows 50 rows per default. We can change this as we like:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odf02zpP06qI"
      },
      "source": [
        "p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfWe0grO06qJ"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVjX2_Iy06qK"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNySrhxP06qK"
      },
      "source": [
        "Find out on wikipedia what this Iris data is about."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwEVzhfl06qK"
      },
      "source": [
        "### Hint\n",
        "\n",
        "There are some ways to get help about modules and methods in Jupyter:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "id": "umgUyQ4i06qL",
        "outputId": "36a41ea5-850e-41cc-ae14-e6a01e1354c1"
      },
      "source": [],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-110-b42447b352cc>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    dataframe. #(tab completion - type tab after the dot to see all methods)\u001b[0m\n\u001b[0m                                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCAPpVAq06qL"
      },
      "source": [
        "Get help about this object, if there is any:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZctEUABs06qL"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5pTPqZA06qM"
      },
      "source": [
        "And, what you will probably use the most, the online package information and examples by googling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dp-beMVD06qM"
      },
      "source": [
        "### Exercise 1.1 (10 min)\n",
        "\n",
        "Read the Swiss BAG Corona data on vaccinated persons into a dataframe and look at it. The URL is\n",
        "https://opendata.swiss/en/dataset/covid-19-schweiz\n",
        "\n",
        "You will probably need to consult https://pandas.pydata.org/docs/reference/io.html in order to find out how to read a json file into a pandas dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjGxXL8k06qM"
      },
      "source": [
        "# Write your code here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIR8YyDP06qM"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCI7ub-706qN"
      },
      "source": [
        "### 3. Indexing on a DataFrame\n",
        "\n",
        "By methods (we are back to our Iris dataset):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0sDmvr006qN"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HglpOox106qN"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jf6gF3jr06qN"
      },
      "source": [
        "Indexing a group/subset of the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvKPHzP106qO"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8holfyZd06qO"
      },
      "source": [
        "**Important**\n",
        "When you assign a (subset) of dataframe to a new one like above, no copy is made. This means that if you change values of the new frame, also the orginal frame will be changed. If you want a copy, you need to use the copy method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9n8pa6UH06qO"
      },
      "source": [
        "Indexing by column names..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZapUeo_x06qO"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0Sqgdk106qP"
      },
      "source": [
        "Selecting (filtering) by column valuess_df = dataframe[dataframe['species']=='Iris-setosa']"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPqUoUYR06qP"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cp2J-Y0E06qP"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IO6qtwYH06qP"
      },
      "source": [
        "Vectorized dataframe manipulations..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dN1twE406qP"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peiXnTgAxw08"
      },
      "source": [
        "Grouping ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPJDgpc006qP"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkS6YD7V06qQ"
      },
      "source": [
        "### 4. Sorting on a DataFrame\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1hGqMMk06qQ"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghnoA6O306qQ"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xGm6-8W06qQ"
      },
      "source": [
        "You may measure the time needed for the execution, e.g. with the operating system command \"time\". System commands are executed with a %:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyaC-Aj006qQ"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbQ1Wuqc06qQ"
      },
      "source": [
        "s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6I2Xd1d06qQ"
      },
      "source": [
        "### 5. Filtering on a DataFrame\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYCwukeI06qR"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjnWw_T406qR"
      },
      "source": [
        "# We can assign the filtering result to a new dataframe\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Widtyr806qR"
      },
      "source": [
        "# And print it\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rg_y8Ift06qR"
      },
      "source": [
        "### 6. Missing or bad data\n",
        "\n",
        "Datasets, in particular before they are \"cleaned\", may contain missing or wrongly formated values. There are DataFrame methods to deal with this:\n",
        "\n",
        "- DataFrame.dropna([axis, how, thresh, 因)\tRemove missing values.\n",
        "- DataFrame.fillna([value, method, axis, 因)\tFill NA/NaN values using the specified method\n",
        "- DataFrame.replace([to_replace, value, 因)\tReplace values given in to_replace with value.\n",
        "- DataFrame.interpolate([method, axis, limit, 因)\tInterpolate values according to different methods.\n",
        "\n",
        "Retrieving and cleaning data is often the most time consuming part in a data science project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HN7OXDjJ06qR"
      },
      "source": [
        "### 7. Exporting dataframes\n",
        "\n",
        "DataFrame has several export methods. (html, hdf5, ascii, excel etc). Let's write our file to a text file in a csv format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhxN8bF_06qR"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-27C7Vz06qR"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-Y9fLm6YYlH"
      },
      "source": [
        "What happens with our files when we close our colab session?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1No9Vhr06qS"
      },
      "source": [
        "### 8. Metadata\n",
        "\n",
        "\n",
        "Metadata is data about the data, e.g. when was it collected, under which conditions, calibration etc.\n",
        "Metadata is normally not part of the statistical data analysis, however, needed for understanding and reproducibilty.\n",
        "\n",
        "DataFrame is not really made for storing metadata (should be done separately), but one can add new attributes to a dataframe:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQ7Q2lT306qS"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpLXCrvn06qS"
      },
      "source": [
        "### Exercise 2\n",
        "\n",
        "Write down here some minimal metadata about the Iris dataset:\n",
        "\n",
        "-\n",
        "-\n",
        "-\n",
        "Summary: everything needed for reproduction\n",
        "\n",
        "(the \"dimensions of a numpy table or dataframe is often called the shape). 150x5x3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gm5NcJsD06qS"
      },
      "source": [
        "### 9. Working on the filesystem with the os module\n",
        "\n",
        "When managing large datasets, one often has to organise files in the file system. This includes finding them, moving and copying them, creating new folders/directories, renaming them etc. This can easily be done from Python with the os (operating system) module.\n",
        "\n",
        "Try to understand the following code and alter it to do something else."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Td_AnJg06qS"
      },
      "source": [
        "import os\n",
        "\n",
        "new_dir = os.getcwd() +'/newnbdir' # Get the current directory into a string, add /newnbdir to the string\n",
        "os.makedirs(new_dir) # Create the folder\n",
        "files = os.listdir() # List the files in the current folder\n",
        "nb_files = [] # Create an empty list\n",
        "for file in files:\n",
        "    if 'ipynb' in file and file[0]!='.':\n",
        "        nb_files.append(file)\n",
        "for file in nb_files:\n",
        "    os.system('cp '+file+' '+new_dir+'/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0mwR_jFZsbk"
      },
      "source": [
        "!ls -l newnbdir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCEPcsaf06qS"
      },
      "source": [
        "### Exercise 3\n",
        "\n",
        "Read in the iris dataset from iris.csv into a dataframe. Set the values in column 1 in row 39, 49 and 100 to NaN (use the nan method from the numpy package). Then replacethe NaN values to the average value of the respective column. Depending on how you do it, this may be about 10 lines of Python code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9VczUOG06qS"
      },
      "source": [
        "# Solve your exercise here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MZXt0ei06qT"
      },
      "source": [
        "### Exercise 4\n",
        "\n",
        "Print a sorted list of the weeks and the male deadths with COVID-19 in Switzerland. The weeks with the highest numbers should appear first. This should be doable with about 10 lines of Python. You may need 30 minutes to solve this one.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UPCsexM06qT"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0G9RWCiH3DLC"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yOZYAHG06qT"
      },
      "source": [
        "# End of today - remember to fill the mandatory form\n",
        "\n",
        "Everyone has to fill this form by 10 pm : https://forms.gle/bzDpGLUieVnheZUi6.\n",
        "Have a nice evening and see you tomorrow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvGsChGa06qT"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPndicDx06qT"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}